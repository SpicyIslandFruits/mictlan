{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T03:46:54.919045Z",
     "start_time": "2024-07-09T03:46:54.469854Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# /home/john/Repositories/mictlan/pkg/ann/processor.go\n",
      "package ann\n",
      "\n",
      "import \"fmt\"\n",
      "\n",
      "type LayerActivations []Number\n",
      "\n",
      "// Context はすべてのActivationを保持している\n",
      "type Context[T any] struct {\n",
      "\tactivations []LayerActivations\n",
      "\tData        T\n",
      "}\n",
      "\n",
      "// NewContext creates a new Context with initialized activations\n",
      "func NewContext[T any](layerSizes []int) *Context[T] {\n",
      "\tactivations := make([]LayerActivations, len(layerSizes))\n",
      "\tfor i, size := range layerSizes {\n",
      "\t\tactivations[i] = make(LayerActivations, size)\n",
      "\t}\n",
      "\treturn &Context[T]{activations: activations}\n",
      "}\n",
      "\n",
      "func (c *Context[T]) Activations() []LayerActivations {\n",
      "\treturn c.activations\n",
      "}\n",
      "\n",
      "func (c *Context[T]) SetActivations(layerIndex int, activations LayerActivations) error {\n",
      "\tif layerIndex < 0 || layerIndex >= len(c.activations) {\n",
      "\t\treturn fmt.Errorf(\"invalid layer index: %d\", layerIndex)\n",
      "\t}\n",
      "\tif len(activations) != len(c.activations[layerIndex]) {\n",
      "\t\treturn fmt.Errorf(\"mismatch in activations length: expected %d, got %d\", len(c.activations[layerIndex]), len(activations))\n",
      "\t}\n",
      "\tc.activations[layerIndex] = activations\n",
      "\treturn nil\n",
      "}\n",
      "\n",
      "// Data は入力層のニューロンの値の配列\n",
      "type Data []Number\n",
      "type Dataset []Data\n",
      "\n",
      "type WeightAdjustmentsToNeuron []Number\n",
      "type WeightAdjustmentsToLayer []WeightAdjustmentsToNeuron\n",
      "type WeightAdjustments []WeightAdjustmentsToLayer\n",
      "\n",
      "type BiasAdjustmentsToNeuron Number\n",
      "type BiasAdjustmentsToLayer []BiasAdjustmentsToNeuron\n",
      "type BiasAdjustments []BiasAdjustmentsToLayer\n",
      "\n",
      "type Adjustments struct {\n",
      "\tweightAdjustments WeightAdjustments\n",
      "\tbiasAdjustments   BiasAdjustments\n",
      "}\n",
      "\n",
      "func NewAdjustments(adjustments WeightAdjustments, biasAdjustments BiasAdjustments) Adjustments {\n",
      "\treturn Adjustments{adjustments, biasAdjustments}\n",
      "}\n",
      "\n",
      "func (a *Adjustments) WeightAdjustments() WeightAdjustments {\n",
      "\treturn a.weightAdjustments\n",
      "}\n",
      "\n",
      "func (a *Adjustments) BiasAdjustments() BiasAdjustments {\n",
      "\treturn a.biasAdjustments\n",
      "}\n",
      "\n",
      "// ActivationCalculator は活性化関数と活性化関数の導関数の値を計算するための構造体のインターフェース\n",
      "type ActivationCalculator interface {\n",
      "\t// Activation は活性化関数の値\n",
      "\tActivation(weightedSum Number) Number\n",
      "\t// Derivative は導関数の値\n",
      "\tDerivative(weightedSum Number) Number\n",
      "}\n",
      "\n",
      "// Labels は教師データ\n",
      "type Labels []Number\n",
      "\n",
      "// Processor では行列計算を行う必要があるためニューロン毎に違うActivationを得ることは不可能\n",
      "type Processor[T any] interface {\n",
      "\tActivationCalculator\n",
      "\tFeedForward(network *Network, dataset Dataset) []Context[T]\n",
      "\tBackPropagate(contexts []Context[T], labels []Labels) Adjustments\n",
      "}\n",
      "\n",
      "\n",
      "# /home/john/Repositories/mictlan/pkg/ann/network_test.go\n",
      "package ann\n",
      "\n",
      "import (\n",
      "\t\"testing\"\n",
      ")\n",
      "\n",
      "func TestNetwork(t *testing.T) {\n",
      "\t// レイヤーを作成\n",
      "\tinputLayer := NewLayer(NewNeurons(28*28, 0))\n",
      "\thiddenLayer1 := NewLayer(NewNeurons(16, 0.1))\n",
      "\thiddenLayer2 := NewLayer(NewNeurons(16, 0.1))\n",
      "\toutputLayer := NewLayer(NewNeurons(10, 0.3))\n",
      "\n",
      "\t// ネットワークを作成\n",
      "\tnetwork := NewNetwork([]*Layer{inputLayer, hiddenLayer1, hiddenLayer2, outputLayer})\n",
      "\n",
      "\t// テスト: レイヤー数が正しいか\n",
      "\tif len(network.Layers()) != 4 {\n",
      "\t\tt.Errorf(\"Expected 3 layers, got %d\", len(network.Layers()))\n",
      "\t}\n",
      "\n",
      "\t// テスト: ニューロン数が各レイヤーで正しいか\n",
      "\tif len(network.Layers()[0].neurons) != 784 {\n",
      "\t\tt.Errorf(\"Expected 784 neurons in input layer, got %d\", len(network.Layers()[0].neurons))\n",
      "\t}\n",
      "\tif len(network.Layers()[1].neurons) != 16 {\n",
      "\t\tt.Errorf(\"Expected 16 neurons in hidden layer, got %d\", len(network.Layers()[1].neurons))\n",
      "\t}\n",
      "\tif len(network.Layers()[2].neurons) != 16 {\n",
      "\t\tt.Errorf(\"Expected 16 neurons in hidden layer, got %d\", len(network.Layers()[1].neurons))\n",
      "\t}\n",
      "\tif len(network.Layers()[3].neurons) != 10 {\n",
      "\t\tt.Errorf(\"Expected 10 neuron in output layer, got %d\", len(network.Layers()[2].neurons))\n",
      "\t}\n",
      "\n",
      "\t// テスト: コネクション数が正しいか\n",
      "\texpectedLayerConnCounts := []int{0, 16, 16, 10}\n",
      "\texpectedConnCounts := []int{0, 784, 16, 16}\n",
      "\n",
      "\tif len(network.Connections()) != len(expectedConnCounts) {\n",
      "\t\tt.Errorf(\"Expected %d connection layers, got %d\", len(expectedConnCounts), len(network.Connections()))\n",
      "\t}\n",
      "\n",
      "\tallConnCounts := 0\n",
      "\tfor layerIndex, layerConn := range network.Connections() {\n",
      "\t\t// それぞれのレイヤーに属するニューロンには、前の層のすべてのニューロンから接続があり、ニューロン毎の配列として保持されているが、配列の個数が正しいか検証\n",
      "\t\tif len(layerConn) != expectedLayerConnCounts[layerIndex] {\n",
      "\t\t\tt.Errorf(\"Expected %d layer connections, got %d\", expectedLayerConnCounts[layerIndex], len(layerConn))\n",
      "\t\t}\n",
      "\n",
      "\t\tfor _, conn := range layerConn {\n",
      "\t\t\t// それぞれのニューロンには、前の層のすべてのニューロンから接続があるが、接続の個数が正しいか検証\n",
      "\t\t\tif len(conn) != expectedConnCounts[layerIndex] {\n",
      "\t\t\t\tt.Errorf(\"Expected %d layer connections, got %d\", expectedConnCounts[layerIndex], len(conn))\n",
      "\t\t\t}\n",
      "\t\t\tallConnCounts += len(conn)\n",
      "\t\t}\n",
      "\t}\n",
      "\n",
      "\texpectedAllConnCounts := 784*16 + 16*16 + 16*10\n",
      "\tif allConnCounts != expectedAllConnCounts {\n",
      "\t\tt.Errorf(\"Expected %d layer connections, got %d\", expectedAllConnCounts, allConnCounts)\n",
      "\t}\n",
      "\n",
      "\t// テスト: UpdateNeuronConnections が正しく動作するか\n",
      "\ttestLayerIndex := 1  // 最初の隠れ層\n",
      "\ttestNeuronIndex := 3 // 最初のニューロン\n",
      "\n",
      "\t// 元の重みを保存\n",
      "\toriginalWeights := make([]Number, len(network.Connections()[testLayerIndex][testNeuronIndex]))\n",
      "\tfor i, conn := range network.Connections()[testLayerIndex][testNeuronIndex] {\n",
      "\t\toriginalWeights[i] = conn.weight\n",
      "\t}\n",
      "\n",
      "\t// テスト用の重み調整値\n",
      "\tweightAdjustments := make([]Number, len(originalWeights))\n",
      "\tfor i := range weightAdjustments {\n",
      "\t\tweightAdjustments[i] = 0.1 // 各重みを0.1増加\n",
      "\t}\n",
      "\n",
      "\t// AdjustNeuronConnections を呼び出し\n",
      "\terr := network.AdjustNeuronConnections(testLayerIndex, testNeuronIndex, weightAdjustments)\n",
      "\tif err != nil {\n",
      "\t\tt.Errorf(\"AdjustNeuronConnections returned an error: %v\", err)\n",
      "\t}\n",
      "\n",
      "\t// 重みが正しく更新されたか確認\n",
      "\tfor i, conn := range network.Connections()[testLayerIndex][testNeuronIndex] {\n",
      "\t\texpectedWeight := originalWeights[i] + 0.1\n",
      "\t\tif conn.weight != expectedWeight {\n",
      "\t\t\tt.Errorf(\"Weight not correctly updated. Expected %f, got %f\", expectedWeight, conn.weight)\n",
      "\t\t}\n",
      "\t}\n",
      "\n",
      "\t// エラーケースのテスト\n",
      "\terr = network.AdjustNeuronConnections(-1, 0, weightAdjustments)\n",
      "\tif err == nil {\n",
      "\t\tt.Error(\"Expected error for invalid layer index, got nil\")\n",
      "\t}\n",
      "\n",
      "\terr = network.AdjustNeuronConnections(testLayerIndex, -1, weightAdjustments)\n",
      "\tif err == nil {\n",
      "\t\tt.Error(\"Expected error for invalid neuron index, got nil\")\n",
      "\t}\n",
      "\n",
      "\terr = network.AdjustNeuronConnections(testLayerIndex, testNeuronIndex, []Number{0.1}) // 不正な長さの調整値\n",
      "\tif err == nil {\n",
      "\t\tt.Error(\"Expected error for mismatched adjustment length, got nil\")\n",
      "\t}\n",
      "}\n",
      "\n",
      "\n",
      "# /home/john/Repositories/mictlan/pkg/ann/network.go\n",
      "package ann\n",
      "\n",
      "import (\n",
      "\t\"fmt\"\n",
      "\t\"math/rand/v2\"\n",
      ")\n",
      "\n",
      "type Number float64\n",
      "\n",
      "type Neuron struct {\n",
      "\tbias Number\n",
      "}\n",
      "\n",
      "func NewNeuron(bias Number) *Neuron {\n",
      "\treturn &Neuron{bias}\n",
      "}\n",
      "\n",
      "func (n *Neuron) Bias() Number {\n",
      "\treturn n.bias\n",
      "}\n",
      "\n",
      "func (n *Neuron) SetBias(bias Number) {\n",
      "\tn.bias = bias\n",
      "}\n",
      "\n",
      "func NewNeurons(count int, bias Number) []*Neuron {\n",
      "\tneurons := make([]*Neuron, count)\n",
      "\tfor i := 0; i < count; i++ {\n",
      "\t\tneurons[i] = NewNeuron(bias)\n",
      "\t}\n",
      "\treturn neurons\n",
      "}\n",
      "\n",
      "type Connection struct {\n",
      "\tfrom   *Neuron\n",
      "\tto     *Neuron\n",
      "\tweight Number\n",
      "}\n",
      "\n",
      "func NewConnection(from *Neuron, to *Neuron, weight Number) *Connection {\n",
      "\treturn &Connection{from, to, weight}\n",
      "}\n",
      "\n",
      "func (c *Connection) Weight() Number {\n",
      "\treturn c.weight\n",
      "}\n",
      "\n",
      "func (c *Connection) AdjustWeight(delta Number) {\n",
      "\t// FIXME: 重みの範囲を制限する必要があるかもしれない\n",
      "\tc.weight += delta\n",
      "}\n",
      "\n",
      "type Layer struct {\n",
      "\tneurons []*Neuron\n",
      "}\n",
      "\n",
      "func NewLayer(neurons []*Neuron) *Layer {\n",
      "\treturn &Layer{neurons: neurons}\n",
      "}\n",
      "\n",
      "func (l *Layer) Neurons() []*Neuron {\n",
      "\treturn l.neurons\n",
      "}\n",
      "\n",
      "// NeuronConnections はあるニューロンに対する前の層からの接続\n",
      "type NeuronConnections []*Connection\n",
      "type LayerConnections []NeuronConnections\n",
      "type Connections []LayerConnections\n",
      "\n",
      "type Network struct {\n",
      "\tlayers []*Layer\n",
      "\t// FIXME: この形式だと代入がだるいので、connectionsの部分テンソル等を\n",
      "\tconnections Connections\n",
      "}\n",
      "\n",
      "func NewNetwork(layers []*Layer, initialWeight ...Number) *Network {\n",
      "\tnetwork := &Network{layers: layers}\n",
      "\tnetwork.Connect(initialWeight...)\n",
      "\treturn network\n",
      "}\n",
      "\n",
      "func (n *Network) Layers() []*Layer {\n",
      "\treturn n.layers\n",
      "}\n",
      "\n",
      "func (n *Network) Connections() Connections {\n",
      "\treturn n.connections\n",
      "}\n",
      "\n",
      "func (n *Network) Connect(initialWeight ...Number) {\n",
      "\tn.connections = make(Connections, len(n.layers))\n",
      "\n",
      "\tfor toLayerIndex := 1; toLayerIndex < len(n.layers); toLayerIndex++ {\n",
      "\t\tfromLayer := n.layers[toLayerIndex-1]\n",
      "\t\ttoLayer := n.layers[toLayerIndex]\n",
      "\n",
      "\t\t// LayerConnectionsの要素は、次の層のニューロン毎に1つ存在する接続の配列なので、次の層のニューロンの数準備する\n",
      "\t\tn.connections[toLayerIndex] = make(LayerConnections, len(toLayer.neurons))\n",
      "\n",
      "\t\tfor toNeuronIndex, toNeuron := range toLayer.neurons {\n",
      "\t\t\t// neuronConnectionsは、次の層の各ニューロンが持つ接続なので、現在の層のすべてのニューロンの数準備する\n",
      "\t\t\tneuronConnections := make(NeuronConnections, len(fromLayer.neurons))\n",
      "\n",
      "\t\t\tfor fromNeuronIndex, fromNeuron := range fromLayer.neurons {\n",
      "\t\t\t\tweight := Number(0)\n",
      "\t\t\t\tif initialWeight != nil {\n",
      "\t\t\t\t\tweight = initialWeight[0]\n",
      "\t\t\t\t} else {\n",
      "\t\t\t\t\tweight = Number(rand.Float64()*2 - 1)\n",
      "\t\t\t\t}\n",
      "\t\t\t\tconnection := NewConnection(fromNeuron, toNeuron, weight)\n",
      "\t\t\t\tneuronConnections[fromNeuronIndex] = connection\n",
      "\t\t\t}\n",
      "\n",
      "\t\t\tn.connections[toLayerIndex][toNeuronIndex] = neuronConnections\n",
      "\t\t}\n",
      "\t}\n",
      "}\n",
      "\n",
      "// TODO: 引数の与え方これが最適化わからないけど何らかの方法で値をセットできるようにする\n",
      "\n",
      "func (n *Network) AdjustNeuronConnections(layerIndex int, neuronIndex int, weightAdjustments []Number) error {\n",
      "\tif layerIndex < 0 || layerIndex >= len(n.connections) {\n",
      "\t\treturn fmt.Errorf(\"invalid layer index: %d\", layerIndex)\n",
      "\t}\n",
      "\n",
      "\tif neuronIndex < 0 || neuronIndex >= len(n.connections[layerIndex]) {\n",
      "\t\treturn fmt.Errorf(\"invalid neuron index: %d for layer %d\", neuronIndex, layerIndex)\n",
      "\t}\n",
      "\n",
      "\tconns := n.connections[layerIndex][neuronIndex]\n",
      "\n",
      "\tif len(weightAdjustments) != len(conns) {\n",
      "\t\treturn fmt.Errorf(\"mismatch in number of adjustments (%d) and connections (%d)\", len(weightAdjustments), len(conns))\n",
      "\t}\n",
      "\n",
      "\tfor index, conn := range conns {\n",
      "\t\tconn.AdjustWeight(weightAdjustments[index])\n",
      "\t}\n",
      "\n",
      "\treturn nil\n",
      "}\n",
      "\n",
      "\n",
      "# /home/john/Repositories/mictlan/gonum/processor.go\n",
      "package gonum\n",
      "\n",
      "import (\n",
      "\t\"gonum.org/v1/gonum/mat\"\n",
      "\t\"math\"\n",
      "\t\"mictlan/pkg/ann\"\n",
      ")\n",
      "\n",
      "type ContextData struct {\n",
      "\tWeights []*mat.Dense\n",
      "\tBiases  []*mat.VecDense\n",
      "}\n",
      "\n",
      "type Processor struct{}\n",
      "\n",
      "func (p Processor) Activation(weightedSum ann.Number) ann.Number {\n",
      "\t// シグモイド関数\n",
      "\treturn ann.Number(1 / (1 + math.Exp(-float64(weightedSum))))\n",
      "}\n",
      "\n",
      "func (p Processor) Derivative(weightedSum ann.Number) ann.Number {\n",
      "\t// シグモイド関数を微分したもの\n",
      "\tactivation := p.Activation(weightedSum)\n",
      "\treturn activation * (1 - activation)\n",
      "}\n",
      "\n",
      "func (p Processor) FeedForward(network *ann.Network, dataset ann.Dataset) []ann.Context[ContextData] {\n",
      "\tcontexts := make([]ann.Context[ContextData], len(dataset))\n",
      "\tlayers := network.Layers()\n",
      "\tconnections := network.Connections()\n",
      "\n",
      "\t// ネットワークの重みと偏りを行列に変換\n",
      "\tweights := make([]*mat.Dense, len(layers)-1)\n",
      "\tbiases := make([]*mat.VecDense, len(layers)-1)\n",
      "\n",
      "\tfor i := 1; i < len(layers); i++ {\n",
      "\t\tlayerConnections := connections[i]\n",
      "\t\trows := len(layerConnections)\n",
      "\t\tcols := len(layerConnections[0])\n",
      "\n",
      "\t\tweightData := make([]float64, rows*cols)\n",
      "\t\tbiasData := make([]float64, rows)\n",
      "\n",
      "\t\tfor j, neuronConns := range layerConnections {\n",
      "\t\t\tfor k, conn := range neuronConns {\n",
      "\t\t\t\tweightData[j*cols+k] = float64(conn.Weight())\n",
      "\t\t\t}\n",
      "\t\t\tbiasData[j] = float64(layers[i].Neurons()[j].Bias())\n",
      "\t\t}\n",
      "\n",
      "\t\tweights[i-1] = mat.NewDense(rows, cols, weightData)\n",
      "\t\tbiases[i-1] = mat.NewVecDense(rows, biasData)\n",
      "\t}\n",
      "\n",
      "\t// ContextDataの作成と格納\n",
      "\tcontextData := ContextData{\n",
      "\t\tWeights: weights,\n",
      "\t\tBiases:  biases,\n",
      "\t}\n",
      "\n",
      "\t// データセットを行列に変換\n",
      "\tdataMatrix := mat.NewDense(len(dataset), len(dataset[0]), nil)\n",
      "\tfor i, data := range dataset {\n",
      "\t\tfor j, val := range data {\n",
      "\t\t\tdataMatrix.Set(i, j, float64(val))\n",
      "\t\t}\n",
      "\t}\n",
      "\n",
      "\t// フィードフォワード計算\n",
      "\tactivations := make([]*mat.Dense, len(layers))\n",
      "\tactivations[0] = dataMatrix\n",
      "\n",
      "\tfor i := 1; i < len(layers); i++ {\n",
      "\t\tprevActivation := activations[i-1]\n",
      "\t\tweight := weights[i-1]\n",
      "\t\tbias := biases[i-1]\n",
      "\n",
      "\t\tweightedSum := mat.NewDense(prevActivation.RawMatrix().Rows, weight.RawMatrix().Rows, nil)\n",
      "\t\tweightedSum.Mul(prevActivation, weight.T())\n",
      "\n",
      "\t\t// バイアスの加算\n",
      "\t\trows, cols := weightedSum.Dims()\n",
      "\t\tbiasMatrix := mat.NewDense(rows, cols, nil)\n",
      "\t\tfor r := 0; r < rows; r++ {\n",
      "\t\t\tbiasMatrix.SetRow(r, bias.RawVector().Data)\n",
      "\t\t}\n",
      "\t\tweightedSum.Add(weightedSum, biasMatrix)\n",
      "\n",
      "\t\t// 活性化関数の適用\n",
      "\t\tactivationFunc := func(_, _ int, v float64) float64 {\n",
      "\t\t\treturn float64(p.Activation(ann.Number(v)))\n",
      "\t\t}\n",
      "\t\tweightedSum.Apply(activationFunc, weightedSum)\n",
      "\n",
      "\t\tactivations[i] = weightedSum\n",
      "\t}\n",
      "\n",
      "\t// 結果をコンテキストに変換\n",
      "\tfor i := range dataset {\n",
      "\t\tlayerSizes := make([]int, len(layers))\n",
      "\t\tfor i, layer := range layers {\n",
      "\t\t\tlayerSizes[i] = len(layer.Neurons())\n",
      "\t\t}\n",
      "\t\tcontext := ann.NewContext[ContextData](layerSizes)\n",
      "\t\tcontext.Data = contextData\n",
      "\t\tfor j, activation := range activations {\n",
      "\t\t\tlayerActivation := make(ann.LayerActivations, activation.RawMatrix().Cols)\n",
      "\t\t\tfor k := 0; k < activation.RawMatrix().Cols; k++ {\n",
      "\t\t\t\tlayerActivation[k] = ann.Number(activation.At(i, k))\n",
      "\t\t\t}\n",
      "\t\t\terr := context.SetActivations(j, layerActivation)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\tpanic(err)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tcontexts[i] = *context\n",
      "\t}\n",
      "\n",
      "\treturn contexts\n",
      "}\n",
      "\n",
      "func (p Processor) BackPropagate(contexts []ann.Context[ContextData], labels []ann.Labels) ann.Adjustments {\n",
      "\tif len(contexts) == 0 || len(labels) != len(contexts) {\n",
      "\t\tpanic(\"Invalid input: contexts and labels must have the same non-zero length\")\n",
      "\t}\n",
      "\n",
      "\tnumLayers := len(contexts[0].Activations())\n",
      "\tweights := contexts[0].Data.Weights\n",
      "\tbatchSize := len(contexts)\n",
      "\n",
      "\t// Initialize weight and bias adjustments\n",
      "\tweightAdjustments := make([]ann.WeightAdjustmentsToLayer, numLayers-1)\n",
      "\tbiasAdjustments := make([]ann.BiasAdjustmentsToLayer, numLayers-1)\n",
      "\n",
      "\t// Convert activations and labels to matrices\n",
      "\tactivations := make([]*mat.Dense, numLayers)\n",
      "\tfor l := 0; l < numLayers; l++ {\n",
      "\t\tlayerSize := len(contexts[0].Activations()[l])\n",
      "\t\tactivationData := make([]float64, batchSize*layerSize)\n",
      "\t\tfor i, context := range contexts {\n",
      "\t\t\tfor j, act := range context.Activations()[l] {\n",
      "\t\t\t\tactivationData[i*layerSize+j] = float64(act)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tactivations[l] = mat.NewDense(batchSize, layerSize, activationData)\n",
      "\t}\n",
      "\n",
      "\tlabelsMatrix := mat.NewDense(batchSize, len(labels[0]), nil)\n",
      "\tfor i, label := range labels {\n",
      "\t\tfor j, val := range label {\n",
      "\t\t\tlabelsMatrix.Set(i, j, float64(val))\n",
      "\t\t}\n",
      "\t}\n",
      "\n",
      "\t// Backpropagation\n",
      "\tdelta := new(mat.Dense)\n",
      "\tdelta.Sub(activations[numLayers-1], labelsMatrix)\n",
      "\n",
      "\tfor l := numLayers - 2; l >= 0; l-- {\n",
      "\t\tprevLayerSize := activations[l].RawMatrix().Cols\n",
      "\t\tcurrentLayerSize := activations[l+1].RawMatrix().Cols\n",
      "\n",
      "\t\t// Calculate weight adjustments\n",
      "\t\tweightAdj := new(mat.Dense)\n",
      "\t\tweightAdj.Mul(activations[l].T(), delta)\n",
      "\t\tweightAdj.Scale(1/float64(batchSize), weightAdj)\n",
      "\n",
      "\t\t// FIXME: でかい行列用意してから、最後にまとめてやったほうが良い気がする\n",
      "\t\tweightAdjustments[l] = make(ann.WeightAdjustmentsToLayer, currentLayerSize)\n",
      "\t\tfor i := 0; i < currentLayerSize; i++ {\n",
      "\t\t\tweightAdjustments[l][i] = make(ann.WeightAdjustmentsToNeuron, prevLayerSize)\n",
      "\t\t\tfor j := 0; j < prevLayerSize; j++ {\n",
      "\t\t\t\tweightAdjustments[l][i][j] = ann.Number(weightAdj.At(j, i))\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\n",
      "\t\t// Calculate bias adjustments\n",
      "\t\tbiasAdj := make(ann.BiasAdjustmentsToLayer, currentLayerSize)\n",
      "\t\tfor i := 0; i < currentLayerSize; i++ {\n",
      "\t\t\tsum := 0.0\n",
      "\t\t\tfor j := 0; j < batchSize; j++ {\n",
      "\t\t\t\tsum += delta.At(j, i)\n",
      "\t\t\t}\n",
      "\t\t\tbiasAdj[i] = ann.BiasAdjustmentsToNeuron(sum / float64(batchSize))\n",
      "\t\t}\n",
      "\t\tbiasAdjustments[l] = biasAdj\n",
      "\n",
      "\t\tif l > 0 {\n",
      "\t\t\t// Prepare delta for the next layer\n",
      "\t\t\tnewDelta := new(mat.Dense)\n",
      "\t\t\t// FeedForwardの時にweightsが転地された状態になってる、statefulなオブジェクトのやり取りは注意が必要\n",
      "\t\t\tnewDelta.Mul(delta, weights[l])\n",
      "\n",
      "\t\t\t// Element-wise multiplication with the derivative of the activation function\n",
      "\t\t\tderivativeActivation := new(mat.Dense)\n",
      "\t\t\tderivativeActivation.Apply(func(_, _ int, v float64) float64 {\n",
      "\t\t\t\treturn float64(p.Derivative(ann.Number(v)))\n",
      "\t\t\t}, activations[l])\n",
      "\n",
      "\t\t\tdelta = new(mat.Dense)\n",
      "\t\t\tdelta.MulElem(newDelta, derivativeActivation)\n",
      "\t\t}\n",
      "\t}\n",
      "\n",
      "\treturn ann.NewAdjustments(weightAdjustments, biasAdjustments)\n",
      "}\n",
      "\n",
      "func NewProcessor() ann.Processor[ContextData] {\n",
      "\treturn Processor{}\n",
      "}\n",
      "\n",
      "\n",
      "# /home/john/Repositories/mictlan/gonum/processor_test.go\n",
      "package gonum\n",
      "\n",
      "import (\n",
      "\t\"math/rand/v2\"\n",
      "\t\"mictlan/pkg/ann\"\n",
      "\t\"testing\"\n",
      ")\n",
      "\n",
      "func TestProcessor(t *testing.T) {\n",
      "\tinputSize := 784\n",
      "\toutputSize := 10\n",
      "\n",
      "\tcreateNetwork := func() *ann.Network {\n",
      "\t\tinputLayer := ann.NewLayer(ann.NewNeurons(inputSize, 0))\n",
      "\t\thiddenLayer1 := ann.NewLayer(ann.NewNeurons(16, 0))\n",
      "\t\thiddenLayer2 := ann.NewLayer(ann.NewNeurons(16, 0))\n",
      "\t\toutputLayer := ann.NewLayer(ann.NewNeurons(outputSize, 0))\n",
      "\n",
      "\t\t// weightをすべて0.1にしてネットワークを作成\n",
      "\t\t// TODO: weightの初期値を複数用意するか、他の方法で極小値に収束するのではなく最小値を探したい\n",
      "\t\treturn ann.NewNetwork([]*ann.Layer{inputLayer, hiddenLayer1, hiddenLayer2, outputLayer})\n",
      "\t}\n",
      "\n",
      "\tnetwork := createNetwork()\n",
      "\toldNetwork := createNetwork()\n",
      "\n",
      "\t// トレインデータを作成\n",
      "\ttrainDataNum := 1000\n",
      "\tdataset := make(ann.Dataset, trainDataNum)\n",
      "\tallLabels := make([]ann.Labels, trainDataNum)\n",
      "\tfor i := range dataset {\n",
      "\t\tdataset[i] = make(ann.Data, inputSize)\n",
      "\t\tfor j := range dataset[i] {\n",
      "\t\t\tdataset[i][j] = ann.Number(rand.Float64()*2 - 1)\n",
      "\t\t}\n",
      "\t\tallLabels[i] = make(ann.Labels, outputSize)\n",
      "\t\tfor j := range allLabels[i] {\n",
      "\t\t\t// 教師データが全部0.0 0.1 0.2 ...0.9\n",
      "\t\t\tallLabels[i][j] = ann.Number(float32(j) * 0.1)\n",
      "\t\t}\n",
      "\t}\n",
      "\n",
      "\tprocessor := NewProcessor()\n",
      "\t// TODO: 学習率を勾配の急さに併せて調節する\n",
      "\tlearningRate := ann.Number(0.1)\n",
      "\n",
      "\t// 50回の学習ループ\n",
      "\tfor epoch := 0; epoch < 1000; epoch++ {\n",
      "\t\tcontexts := processor.FeedForward(network, dataset)\n",
      "\t\tadjustments := processor.BackPropagate(contexts, allLabels)\n",
      "\n",
      "\t\t// ネットワークの重みを調整\n",
      "\t\tfor layerIndex, layerAdjustments := range adjustments.WeightAdjustments() {\n",
      "\t\t\tfor neuronIndex, neuronAdjustments := range layerAdjustments {\n",
      "\t\t\t\tscaledAdjustments := make([]ann.Number, len(neuronAdjustments))\n",
      "\t\t\t\tfor i, adj := range neuronAdjustments {\n",
      "\t\t\t\t\tscaledAdjustments[i] = -learningRate * adj\n",
      "\t\t\t\t}\n",
      "\n",
      "\t\t\t\terr := network.AdjustNeuronConnections(layerIndex+1, neuronIndex, scaledAdjustments)\n",
      "\t\t\t\tif err != nil {\n",
      "\t\t\t\t\tt.Errorf(\"Error adjusting neuron connections: %v\", err)\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\n",
      "\t\t// バイアスの調整\n",
      "\t\tfor layerIndex, layerBiasAdjustments := range adjustments.BiasAdjustments() {\n",
      "\t\t\tfor neuronIndex, biasAdjustment := range layerBiasAdjustments {\n",
      "\t\t\t\tneuron := network.Layers()[layerIndex+1].Neurons()[neuronIndex]\n",
      "\t\t\t\tscaledBiasAdjustment := -learningRate * ann.Number(biasAdjustment)\n",
      "\t\t\t\tnewBias := neuron.Bias() + scaledBiasAdjustment\n",
      "\t\t\t\tneuron.SetBias(newBias)\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\n",
      "\t\t// 10エポックごとに進捗を表示\n",
      "\t\tif epoch%10 == 0 {\n",
      "\t\t\tt.Logf(\"Completed epoch %d\", epoch)\n",
      "\t\t}\n",
      "\t}\n",
      "\n",
      "\tt.Log(\"Training completed - 50 epochs\")\n",
      "\n",
      "\ttestDataset := make(ann.Dataset, 1)\n",
      "\tfor i := range testDataset {\n",
      "\t\ttestDataset[i] = make(ann.Data, inputSize)\n",
      "\t\tfor j := range testDataset[i] {\n",
      "\t\t\ttestDataset[i][j] = ann.Number(rand.Float64()*2 - 1)\n",
      "\t\t}\n",
      "\t}\n",
      "\n",
      "\t// 何を入力しても教師データの0 0.1 0.2 ...0.9という形式に近い出力になるはず\n",
      "\tfinalContexts := processor.FeedForward(network, testDataset)\n",
      "\tt.Logf(\"Final output after training: %+v\", finalContexts[0].Activations()[len(finalContexts[0].Activations())-1])\n",
      "\n",
      "\t// トレーニングしていないモデルではでたらめな出力になる\n",
      "\trandomContexts := processor.FeedForward(oldNetwork, testDataset)\n",
      "\tt.Logf(\"Output of model before training: %+v\", randomContexts[0].Activations()[len(randomContexts[0].Activations())-1])\n",
      "}\n",
      "\n",
      "\n",
      "# /home/john/Repositories/mictlan/internal/digitguesser/app.go\n",
      "package digitguesser\n",
      "\n",
      "import (\n",
      "\t\"math/rand\"\n",
      "\t\"mictlan/pkg/ann\"\n",
      ")\n",
      "\n",
      "const (\n",
      "\tInputSize           = 28 * 28\n",
      "\tHiddenLayer1Size    = 16\n",
      "\tHiddenLayer2Size    = 16\n",
      "\tOutputLayerSize     = 10\n",
      "\tBatchSize           = 1000\n",
      "\tInitialLearningRate = ann.Number(5)\n",
      "\tMinLearningRate     = 0.02\n",
      "\tLearningRateDecay   = 0.99\n",
      ")\n",
      "\n",
      "type App[T any] struct {\n",
      "\tnetwork   *ann.Network\n",
      "\tprocessor ann.Processor[T]\n",
      "\tdataset   ann.Dataset\n",
      "\tlabels    []ann.Labels\n",
      "}\n",
      "\n",
      "func NewApp[T any](processor ann.Processor[T], dataset ann.Dataset, labels []ann.Labels) *App[T] {\n",
      "\t// レイヤーを作成\n",
      "\tinputLayer := ann.NewLayer(ann.NewNeurons(InputSize, 0.1))\n",
      "\thiddenLayer1 := ann.NewLayer(ann.NewNeurons(HiddenLayer1Size, 0.1))\n",
      "\t//hiddenLayer2 := ann.NewLayer(ann.NewNeurons(HiddenLayer2Size, 0.1))\n",
      "\toutputLayer := ann.NewLayer(ann.NewNeurons(OutputLayerSize, 0.1))\n",
      "\n",
      "\t// ネットワークを作成\n",
      "\tnetwork := ann.NewNetwork([]*ann.Layer{inputLayer, hiddenLayer1, outputLayer})\n",
      "\n",
      "\treturn &App[T]{\n",
      "\t\tnetwork:   network,\n",
      "\t\tprocessor: processor,\n",
      "\t\tdataset:   dataset,\n",
      "\t\tlabels:    labels,\n",
      "\t}\n",
      "}\n",
      "\n",
      "func (a *App[T]) Train(epochs int) error {\n",
      "\tlearningRate := InitialLearningRate\n",
      "\n",
      "\tfor epoch := 0; epoch < epochs; epoch++ {\n",
      "\t\t// ミニバッチの作成\n",
      "\t\tbatchData, batchLabels := a.createMiniBatch()\n",
      "\n",
      "\t\t// フィードフォワードとバックプロパゲーション\n",
      "\t\tcontexts := a.processor.FeedForward(a.network, batchData)\n",
      "\t\tadjustments := a.processor.BackPropagate(contexts, batchLabels)\n",
      "\n",
      "\t\t// ネットワークの更新\n",
      "\t\terr := a.updateNetwork(adjustments, learningRate)\n",
      "\t\tif err != nil {\n",
      "\t\t\treturn err\n",
      "\t\t}\n",
      "\n",
      "\t\t// 学習率の更新\n",
      "\t\tlearningRate = a.updateLearningRate(learningRate, epoch)\n",
      "\t}\n",
      "\n",
      "\treturn nil\n",
      "}\n",
      "\n",
      "func (a *App[T]) createMiniBatch() (ann.Dataset, []ann.Labels) {\n",
      "\tindices := rand.Perm(len(a.dataset))[:BatchSize]\n",
      "\tbatchData := make(ann.Dataset, BatchSize)\n",
      "\tbatchLabels := make([]ann.Labels, BatchSize)\n",
      "\n",
      "\tfor i, idx := range indices {\n",
      "\t\tbatchData[i] = a.dataset[idx]\n",
      "\t\tbatchLabels[i] = a.labels[idx]\n",
      "\t}\n",
      "\n",
      "\treturn batchData, batchLabels\n",
      "}\n",
      "\n",
      "func (a *App[T]) updateNetwork(adjustments ann.Adjustments, learningRate ann.Number) error {\n",
      "\t// 重みの更新\n",
      "\tfor layerIndex, layerAdjustments := range adjustments.WeightAdjustments() {\n",
      "\t\tfor neuronIndex, neuronAdjustments := range layerAdjustments {\n",
      "\t\t\tscaledAdjustments := make([]ann.Number, len(neuronAdjustments))\n",
      "\t\t\tfor i, adj := range neuronAdjustments {\n",
      "\t\t\t\tscaledAdjustments[i] = -learningRate * adj\n",
      "\t\t\t}\n",
      "\t\t\terr := a.network.AdjustNeuronConnections(layerIndex+1, neuronIndex, scaledAdjustments)\n",
      "\t\t\tif err != nil {\n",
      "\t\t\t\treturn err\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t}\n",
      "\n",
      "\t// バイアスの更新\n",
      "\tfor layerIndex, layerBiasAdjustments := range adjustments.BiasAdjustments() {\n",
      "\t\tfor neuronIndex, biasAdjustment := range layerBiasAdjustments {\n",
      "\t\t\tneuron := a.network.Layers()[layerIndex+1].Neurons()[neuronIndex]\n",
      "\t\t\tscaledBiasAdjustment := -learningRate * ann.Number(biasAdjustment)\n",
      "\t\t\tnewBias := neuron.Bias() + scaledBiasAdjustment\n",
      "\t\t\tneuron.SetBias(newBias)\n",
      "\t\t}\n",
      "\t}\n",
      "\n",
      "\treturn nil\n",
      "}\n",
      "\n",
      "func (a *App[T]) updateLearningRate(currentRate ann.Number, epoch int) ann.Number {\n",
      "\tnewRate := currentRate * LearningRateDecay\n",
      "\tif newRate < MinLearningRate {\n",
      "\t\treturn MinLearningRate\n",
      "\t}\n",
      "\treturn newRate\n",
      "}\n",
      "\n",
      "func (a *App[T]) Predict(input ann.Data) ann.LayerActivations {\n",
      "\tdataset := make(ann.Dataset, 1)\n",
      "\tdataset[0] = input\n",
      "\tcontext := a.processor.FeedForward(a.network, dataset)[0]\n",
      "\treturn context.Activations()[len(context.Activations())-1]\n",
      "}\n",
      "\n",
      "\n",
      "# /home/john/Repositories/mictlan/cmd/digitguesser/main.go\n",
      "package main\n",
      "\n",
      "import (\n",
      "\t\"fmt\"\n",
      "\t\"log\"\n",
      "\t\"mictlan/gonum\"\n",
      "\t\"mictlan/internal/digitguesser\"\n",
      "\t\"mictlan/mnist\"\n",
      "\t\"mictlan/pkg/ann\"\n",
      ")\n",
      "\n",
      "func main() {\n",
      "\tdataset, labels, err := mnist.LoadData(\"C:\\\\Users\\\\spicy\\\\IdeaProjects\\\\mictlan\\\\mnist\\\\data\")\n",
      "\tif err != nil {\n",
      "\t\tlog.Fatalf(\"Failed to load MNIST data: %v\", err)\n",
      "\t}\n",
      "\tfmt.Printf(\"Dataset size: %d, Labels size: %d\\n\", len(dataset), len(labels))\n",
      "\n",
      "\tprocessor := gonum.NewProcessor()\n",
      "\tguesser := digitguesser.NewApp(processor, dataset[:60000], labels[:60000])\n",
      "\n",
      "\t// 学習の実行\n",
      "\terr = guesser.Train(2000)\n",
      "\tif err != nil {\n",
      "\t\tpanic(err)\n",
      "\t}\n",
      "\n",
      "\t// テストデータでの予測と正答率の計算\n",
      "\tcorrect := 0\n",
      "\ttotal := 0\n",
      "\tfor i := 60000; i < 70000; i++ {\n",
      "\t\tprediction := guesser.Predict(dataset[i])\n",
      "\n",
      "\t\tpredictedIndex := maxIndex(prediction)\n",
      "\t\tactualIndex := maxIndex(labels[i])\n",
      "\n",
      "\t\tif predictedIndex == actualIndex {\n",
      "\t\t\tcorrect++\n",
      "\t\t}\n",
      "\t\ttotal++\n",
      "\n",
      "\t\t// 予測結果の表示（オプション）\n",
      "\t\t//fmt.Printf(\"Sample %d: Predicted %d, Actual %d, %v\\n\", i, predictedIndex, actualIndex, predictedIndex == actualIndex)\n",
      "\t}\n",
      "\n",
      "\t// 正答率の計算と表示\n",
      "\taccuracy := float64(correct) / float64(total) * 100\n",
      "\tfmt.Printf(\"\\nAccuracy: %.2f%% (%d/%d)\\n\", accuracy, correct, total)\n",
      "}\n",
      "\n",
      "// maxIndex は与えられたスライスの中で最大値のインデックスを返す\n",
      "func maxIndex(slice []ann.Number) int {\n",
      "\tmaxVal := slice[0]\n",
      "\tmaxIdx := 0\n",
      "\tfor i, val := range slice {\n",
      "\t\tif val > maxVal {\n",
      "\t\t\tmaxVal = val\n",
      "\t\t\tmaxIdx = i\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn maxIdx\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# claudeのcontextに貼れるようにannのファイルを全部出力\n",
    "\n",
    "import localfile\n",
    "\n",
    "\n",
    "# List of directories to process\n",
    "directories = [\n",
    "    \"pkg/ann\",\n",
    "    \"gonum\",\n",
    "    \"internal/digitguesser\",\n",
    "    \"cmd/digitguesser\"\n",
    "]\n",
    "\n",
    "# Process each directory\n",
    "for directory in directories:\n",
    "    localfile.print_source(directory, \".go\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
